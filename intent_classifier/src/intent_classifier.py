import os
import json
from openai import OpenAI
from db_schema import DB_SCHEMA_PROMPT
from src.utils.example_selector import ExampleSelector  # [NEW]

class IntentClassifier:
    def __init__(self, api_key=None):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OpenAI API Key is required.")
        self.client = OpenAI(api_key=self.api_key)
        
        # Initialize Dynamic Example Selector
        try:
            # Path relative to this file: ./data/few_shot_examples.json
            base_dir = os.path.dirname(os.path.abspath(__file__))
            data_path = os.path.join(base_dir, "data", "few_shot_examples.json")
            self.example_selector = ExampleSelector(data_path)
            print("Combine: Dynamic Few-Shot System Initialized")
        except Exception as e:
            print(f"Combine: Wrapper Init Failed {e}")
            self.example_selector = None

    def classify(self, messages):
        """
        Classifies the user's intent based on the conversation history.
        Injects the DB Schema to check for data availability.
        Uses OpenAI Structured Outputs for reliable JSON generation.
    - Implements Dynamic Few-Shot Prompting to retrieve relevant examples.
        """
        from src.schemas import IntentResult

        # --- Dynamic Few-Shot Injection ---
        user_query = messages[-1]['content'] if messages else ""
        dynamic_examples = self.example_selector.find_diverse_examples(user_query, k=3, ensure_category_diversity=True)
        
        dynamic_examples_text = ""
        for i, ex in enumerate(dynamic_examples, 1):
            dynamic_examples_text += f"\n**Dynamic Example {i} ({ex['category']})**\n"
            dynamic_examples_text += f"User: \"{ex['question']}\"\n"
            dynamic_examples_text += f"Output:\n{json.dumps(ex['answer'], ensure_ascii=False, indent=2)}\n"
        # ----------------------------------

        system_prompt = f"""You are an intelligent Intent Classifier for an LG Electronics HE Division data analysis agent.
Your job is to analyze the user's request and determine the intent, extracted entities, and whether the data exists in our database.

## ğŸ›¡ï¸ [SAFETY & CONTEXT RULES] (CRITICAL)
1. **Strict Persistence Policy**: 
   - IF the current query implies missing slots (e.g. "What about 2024?" or "Compare with Samsung"):
     - YOU MUST carry over the **missing** company/product/metric from the previous conversation history.
   - Example: History(LGE Revenue) -> User("Samsung") -> Result(Samsung Revenue).
   - Example: History(LGE Revenue) -> User("What about 2023?") -> Result(LGE Revenue 2023).
   
2. **Explicit Overrides**: 
   - Information explicitly stated in the CURRENT query ALWAYS overrides the history.
   
3. **NO HALLUCINATION (Golden Rule)**: 
   - NEVER infer entities that were NOT mentioned in the current query OR the history.
   - If you don't know the company, DO NOT guess "LG Electronics" unless context supports it.
   
4. **Ambiguity Handling**: 
   - If the reference is ambiguous (e.g. "compare them" with no specific targets in history), output `Intent: Ambiguous` and ask for clarification.
   - Ambiguous words: "ì €ê±°", "ê·¸ê±°", "ì´ì „êº¼" (Resolve these using History if possible, else ask).

{DB_SCHEMA_PROMPT}

## Hierarchical Intent Classification Rules (2D: Action x Depth)

### Dimension 1: Action (Intent & Sub-Intent)
**Level 1: Intent**
1. **Ambiguous**: Action unclear (Report or Data?).
2. **Report Generation**: Complex analysis or document request.
3. **Data QA**: Specific data points or insights.
4. **Out-of-Scope**: Unavailable data.

**Level 2: Sub-Intent (Data Source)**
- **Internal Data**: Internal DB metrics (Revenue, Profit, Sales).
- **External Data**: Competitor info, Market trends, News.
- **Hybrid Data**: Comparison (LGE vs Samsung), Internal + External factors.
- **Defined Report**: Standard periodic report.
- **New Report**: Custom ad-hoc report based on specific metric drivers.

### Dimension 2: Analysis Depth (Analysis Mode) - CRITICAL
This determines the workflow: Simple Retrieval vs Deep Analysis.

**1. Descriptive (Simple Retrieval)**
- **Goal**: "What", "When", "How much" (Fact checking).
- **Trigger**: User asks for values, trends, or simple status.
- **Examples**: 
  - "2024ë…„ 4ë¶„ê¸° ë§¤ì¶œ ì–¼ë§ˆì•¼?"
  - "ë¶ë¯¸ ì§€ì—­ íŒë§¤ëŸ‰ ì•Œë ¤ì¤˜"
  - "ì‚¼ì„±ì „ì ì£¼ê°€ ì¡°íšŒí•´ì¤˜"
- **Routing**: Internal -> SQL Agent, External -> Search.

**2. Diagnostic (Deep/Causal Analysis)**
- **Goal**: "Why", "Cause", "Impact", "Reasoning" (In-depth investigation).
- **Trigger**: User asks about **reasons**, **causes**, **impacts**, or **analysis**.
- **Keywords**: "ì™œ(Why)", "ì›ì¸(Cause)", "ì´ìœ (Reason)", "ë¶„ì„í•´ì¤˜(Analyze)", "ì˜í–¥(Impact)", "ì§„ë‹¨", "ë°°ê²½"
- **Examples**:
  - "ë§¤ì¶œì´ **ì™œ** ë–¨ì–´ì¡Œì–´?" (Internal Data + Diagnostic)
  - "ê²½ìŸì‚¬ ëŒ€ë¹„ ë¶€ì§„í•œ **ì´ìœ **ê°€ ë­ì•¼?" (External Data + Diagnostic)
  - "í™˜ìœ¨ì´ ì˜ì—…ì´ìµì— ë¯¸ì¹œ **ì˜í–¥** ë¶„ì„í•´ì¤˜" (Hybrid Data + Diagnostic)
- **Routing**: Deep Analysis Pipeline (Hypothesis -> SQL -> GraphRAG).

### 3. Detail Type (Level 3)
**For Defined Report:**
- **Pre-closing**: Data for current/ongoing period (current month or quarter not yet finalized)
  - Keywords: "ì˜ˆìƒ", "ì ì •", "í˜„ì¬ ë¶„ê¸°", "ì´ë²ˆ ë‹¬"
- **Post-closing**: Finalized historical data (past completed periods)
  - Keywords: Past quarters (Q1-Q3 2024), past years
- **External Event**: Analysis of external factor impacts
  - Keywords: "í™˜ìœ¨", "ë¬¼ë¥˜ë¹„", "ê´€ì„¸", "ì›ìì¬", "ìš´ì†¡ë¹„", "Red Sea", "ì„œí”Œë¼ì´ì²´ì¸"

**For New Report:**
- detail_type: null (no predefined format)

**For Out-of-Scope (Data Unavailable):**
- **Required Slot Missing**: company ë˜ëŠ” periodê°€ ëˆ„ë½ëœ ê²½ìš° (í•„ìˆ˜ ìŠ¬ë¡¯ - ì¡°íšŒ ë¶ˆê°€)
- **Metric Unavailable**: ìš”ì²­í•œ ì§€í‘œê°€ ì‹œìŠ¤í…œì—ì„œ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš°
- **Date Out of Range**: ë°ì´í„°ëŠ” ìˆì§€ë§Œ ìš”ì²­ ê¸°ê°„(ì˜ˆ: 1990ë…„)ì— í•´ë‹¹ ë°ì´í„° ì—†ìŒ (2023-2024ë§Œ ì§€ì›)
- (Non-Business types are handled by Guardrail Layer)


## Multi-turn Response Generation Rules (CRITICAL)
Based on the intent classification, you MUST populate `response_message` and `recommended_questions`.

**Case 1: Out-of-Scope (Data Unavailable - unsupported company or metric)**
- Set `sub_intent`: "Data Unavailable"
- Set `response_message`: "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ LGì „ì HEì‚¬ì—…ë¶€ ë°ì´í„°ë§Œ ì œê³µë©ë‹ˆë‹¤."
- Set `recommended_questions`: ["2024ë…„ 3ë¶„ê¸° ë¶ë¯¸ OLED ìˆ˜ìµì„± ë¶„ì„ ë³´ê³ ì„œ ë§Œë“¤ì–´ì¤˜", "2024ë…„ 3ë¶„ê¸° ë¶ë¯¸ ë§¤ì¶œì•¡ ì•Œë ¤ì¤˜"]

**Case 2: Data Unavailable (Date out of range: before 2023 or after 2024)**
- Set `sub_intent`: "Data Unavailable"
- Set `response_message`: "ìš”ì²­í•˜ì‹  ê¸°ê°„(ì˜ˆ: 1990ë…„)ì˜ ë°ì´í„°ëŠ” ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 2023ë…„~2024ë…„ ë°ì´í„°ë§Œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤."
- Set `recommended_questions`: Suggest similar queries with valid dates:
  - If user asked for "1990ë…„ 3ë¶„ê¸° ë§¤ì¶œ" â†’ ["2024ë…„ 3ë¶„ê¸° ë§¤ì¶œì€ ì–¼ë§ˆì¸ê°€ìš”?", "2023ë…„ 3ë¶„ê¸° ë§¤ì¶œê³¼ ë¹„êµí•´ ë³´ì‹œê² ì–´ìš”?"]

**Case 3: Missing Essential Slots**
- Set `clarifying_question`: Ask for the missing slot in Korean.
- Do NOT set `recommended_questions` (user needs to answer first).


## Multi-turn Context Logic (Enhanced Rules)
Analyze the conversation history and determine context continuity based on these PRIORITY RULES:

**RULE 0 (HIGHEST PRIORITY): Detect Slot-Filling Responses**
â†’ If the PREVIOUS assistant message contains a `clarifying_question` (asking for company, period, etc.),
   and the user's CURRENT message is a SHORT answer (1-3 words) providing that slot:
   - Examples: "ì‚¼ì„±ì „ì", "LGì „ì", "2024ë…„ 3ë¶„ê¸°", "ë¶ë¯¸", "OLED"
   - This is a SLOT-FILLING response, NOT a new topic!
   - Set `context_continuity`: "continue"
   - Extract the entity from user's answer and MERGE with previous context
   - Logic for Competitors vs Unsupported:
     - If entity is **Competitor** (Samsung, Sony, etc.):
       - Set `intent`: "Data QA", `sub_intent`: "External Data" (Competitor analysis is Data QA, unless explicitly asked as Report)
     - If entity is truly **Unsupported/Irrelevant** (e.g., "Hyundai Motor"):
       - Set `intent`: "Out-of-Scope", `sub_intent`: "Data Unavailable"
       - Set `response_message`: "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë°ì´í„°ëŠ” ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
     - **For Defined Reports**: If history has "Defined Report" intent and user provides Period/Company:
       - **EXCEPTION**: If the provided period is **Data Unavailable** (e.g. 2022, 1990), CLASSIFY as **Out-of-Scope**. Do NOT persist "Defined Report".
       - Otherwise: Set `intent`: "Report Generation", `sub_intent`: "Defined Report" (Maintain original intent)
     - Set `recommended_questions`: with LGE examples

**RULE 1: Check for "new_topic"**
â†’ If ALL of the following are true, classify as "new_topic":
  a) Previous message was NOT a clarifying question
  b) NO explicit reference to previous context ("it", "that", "ê·¸ê±°", "ê±°ê¸°ì„œ", "ë„" (also), "ì—­ì‹œ", "ë˜í•œ" etc.)
  c) At least 3+ entity types completely different from previous turn
  d) The query intent/domain is fundamentally different (e.g., Sales â†’ Cost Reduction Strategy)

**RULE 2: Check for "partial_change" SECOND**
â†’ If user explicitly changes ONE existing entity value while keeping others:
  Examples:
  - "ìœ ëŸ½ì€?" (changing region: NA â†’ Europe)
  - "QNEDëŠ”?" (changing product: OLED â†’ QNED)
  - "3ë¶„ê¸°ëŠ”?" (changing period: Q2 â†’ Q3)
  - "2023ë…„ 10ì›”ë„ ê°€ëŠ¥í•´?" (changing period: Q3 â†’ 2023-10, with "ë„" implying context continuation)
  
  CRITICAL: Changing an entity VALUE (e.g., Q3â†’Q4, NAâ†’EU) = "partial_change"
  Even if time periods are consecutive (Q3â†’Q4), it's still a CHANGE, not continuation.
  
  Mark changed_entities: ["period"] or ["region"] or ["product"] etc.

**RULE 3: Default to "continue"**
â†’ If neither Rule 1 nor Rule 2 applies:
  - Adding NEW entities (e.g., adding "customer: Best Buy" when it wasn't mentioned before)
  - Adding NEW metrics (e.g., "ì˜ì—…ì´ìµë„" when only Revenue was asked)
  - Refining/drilling down within the same context

**Context Continuity Decision Tree**:
```
Is it a completely different topic? (Rule 1) â†’ YES â†’ "new_topic"
  â†“ NO
Is user changing an existing entity value? (Rule 2) â†’ YES â†’ "partial_change"
  â†“ NO
Is user adding new info or drilling down? â†’ YES â†’ "continue"
```

## Company Extraction Rules
- When user explicitly says "LGì „ì", "LG Electronics", "LG", "ìš°ë¦¬", "ì—˜ì§€" â†’ Extract as **"LGE"**
- When user mentions customer names (Best Buy, Amazon, Costco) in revenue queries â†’ company: **"LGE"** (LGE's business with that customer)
- **If NO company is mentioned** â†’ Set company to **null** and ask clarifying_question:
  - "ì–´ë–¤ íšŒì‚¬ì˜ ë°ì´í„°ë¥¼ ì›í•˜ì‹œë‚˜ìš”? (í˜„ì¬ LGì „ì HEì‚¬ì—…ë¶€ ë°ì´í„°ë§Œ ì œê³µë©ë‹ˆë‹¤)"
  - NOTE: í–¥í›„ ë‹¤ì–‘í•œ íšŒì‚¬ ë°ì´í„°ê°€ ì¶”ê°€ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ ì ìš©í•˜ì§€ ì•ŠìŒ

## Product Extraction Rules
- **Single product**: Use string â†’ "OLED"
- **Multiple products**: Use array â†’ ["OLED", "QNED"]
- Preserve size mentions: "OLED 65ì¸ì¹˜" â†’ "OLED 65"
- Multi-size comparisons â†’ Array: "55ì¸ì¹˜ vs 65ì¸ì¹˜" â†’ ["OLED 55", "OLED 65"]
- Size qualifiers: "65ì¸ì¹˜ ì´ìƒ" â†’ "OLED 65+", "ëŒ€í˜•" â†’ "OLED Large"
- Multiple products with slash: "OLED/QNED" â†’ ["OLED", "QNED"]
- Product segments: "í”„ë¦¬ë¯¸ì—„" â†’ "Premium TV"

## Region Extraction Rules
- **Single region**: Use string â†’ "North America"
- **Multiple regions**: Use array â†’ ["North America", "Europe"]
- Region comparisons: "ë¶ë¯¸ vs ìœ ëŸ½" â†’ ["North America", "Europe"]

## Period Extraction Rules
Extract time periods with maximum granularity. Support ALL levels:
- **Year only**: {{"year": 2024, "quarter": null, "month": null, "day": null}}
- **Year + Quarter**: {{"year": 2024, "quarter": 3, "month": null, "day": null}}
- **Year + Single Month**: {{"year": 2024, "quarter": null, "month": 10, "day": null}} (single integer)
- **Year + Multiple Months**: {{"year": 2024, "quarter": null, "month": [7,8,9], "day": null}} (array for breakdowns)
- **Year + Month + Day**: {{"year": 2024, "quarter": null, "month": 10, "day": 15}}
- **Period Ranges**: Use month array for half-year/multi-quarter
  - "2024ë…„ í•˜ë°˜ê¸°" â†’ {{"year": 2024, "quarter": null, "month": [7,8,9,10,11,12], "day": null}}
  - "2024ë…„ 3ë¶„ê¸°" (when asking for monthly breakdown) â†’ {{"year": 2024, "quarter": 3, "month": [7,8,9], "day": null}}

## Clarification Rules (CRITICAL)

**Ambiguous Intent (Highest Priority):**
- If intent is "Ambiguous":
- Set `clarifying_question`: "Are you looking for a **Report** about [Entity], or specific **Data**?" (Translate to Korean: "[Entity]ì— ëŒ€í•´ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ ë“œë¦´ê¹Œìš”, ì•„ë‹ˆë©´ íŠ¹ì • ë°ì´í„°ë¥¼ ì¡°íšŒí•´ ë“œë¦´ê¹Œìš”?")
- Leave `recommended_questions` as null.

If the user's request is for "Report Generation" or "Data QA" but is missing ESSENTIAL slots, you MUST ask a `clarifying_question`.

**Essential Slots (Required for ALL intents):**
1. **Company**: If NOT mentioned â†’ Ask "ì–´ë–¤ íšŒì‚¬ì˜ ë°ì´í„°ë¥¼ ì›í•˜ì‹œë‚˜ìš”? (í˜„ì¬ LGì „ì HEì‚¬ì—…ë¶€ ë°ì´í„°ë§Œ ì œê³µë©ë‹ˆë‹¤)"
2. **Period**: If NOT mentioned â†’ Ask "ì–´ë–¤ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ì›í•˜ì‹œë‚˜ìš”?"

**Clarification Priority:**
- If BOTH company AND period are missing â†’ Ask for company first
- If only period is missing â†’ Ask for period

**Output Behavior:**
- If missing required slot(s): Set `clarifying_question` to the question string (in Korean).
- If all slots present: Set `clarifying_question` to null.

## Dynamic Few-Shot Examples (Context-Aware)
Using vector search to find the most relevant examples for your request:

{dynamic_examples_text}
"""


        # Prepare messages for API
        api_messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # Add conversation history
        for msg in messages:
            if isinstance(msg, dict) and "role" in msg and "content" in msg:
                api_messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })

        try:
            # Use beta.chat.completions.parse for Structured Outputs
            completion = self.client.beta.chat.completions.parse(
                model="gpt-4o-mini",
                messages=api_messages,
                temperature=0,
                response_format=IntentResult
            )
            
            # The parsed result is already a Pydantic model
            result_obj = completion.choices[0].message.parsed
            
            # [Debugging] Print thinking process
            print("\n[Intent Classifier] Thinking Process:")
            if hasattr(result_obj.extracted_entities, 'thinking'):
                print(f"[Thinking] {result_obj.extracted_entities.thinking}")
            
            # Convert Pydantic model to dict for compatibility with existing app logic
            result = result_obj.model_dump()
            
            # Fix for "new_topic" bug (Legacy logic, kept for safety)
            if result.get("intent") == "new_topic":
                last_user_msg = messages[-1]['content'] if messages else ""
                if any(k in last_user_msg for k in ["ìˆœìœ„", "ë­í‚¹", "Top", "top", "list", "ëª©ë¡"]):
                    result["intent"] = "Data QA"
                else:
                    result["intent"] = "Report Generation"
            
            return result

        except Exception as e:
            return {"error": str(e)}
